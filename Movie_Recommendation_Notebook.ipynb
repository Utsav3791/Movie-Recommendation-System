{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#importing the required libraries\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "import Matrix_Factorization\r\n",
    "import scipy.sparse as sp\r\n",
    "from scipy.sparse.linalg import svds"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matrix_factorization_utilities'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9a37ab2640f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatrix_factorization_utilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msvds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matrix_factorization_utilities'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Reading the ratings data\r\n",
    "ratings = pd.read_csv('Dataset/Ratings.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(ratings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Just taking the required columns\r\n",
    "ratings = ratings[['userId', 'movieId','rating']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking if the user has rated the same movie twice, in that case we just take max of them\r\n",
    "ratings_df = ratings.groupby(['userId','movieId']).aggregate(np.max)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# In this case there are no such cases where the user has rated the same movie twice.\r\n",
    "len(ratings_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Inspecting the data\r\n",
    "ratings.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Counting no of unique users\n",
    "len(ratings['userId'].unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Getting the percentage count of each rating value \n",
    "count_ratings = ratings.groupby('rating').count()\n",
    "count_ratings['perc_total']=round(count_ratings['userId']*100/count_ratings['userId'].sum(),1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count_ratings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Visualising the percentage total for each rating\n",
    "count_ratings['perc_total'].plot.bar()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#reading the movies dataset\n",
    "movie_list = pd.read_csv('Dataset/Movies.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(movie_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# insepcting the movie list dataframe\n",
    "movie_list.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# reading the tags datast\n",
    "tags = pd.read_csv('Dataset/Tags.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# inspecting the tags data frame\n",
    "tags.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# inspecting various genres\n",
    "genres = movie_list['genres']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genres.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "genre_list = \"\"\n",
    "for index,row in movie_list.iterrows():\n",
    "        genre_list += row.genres + \"|\"\n",
    "#split the string into a list of values\n",
    "genre_list_split = genre_list.split('|')\n",
    "#de-duplicate values\n",
    "new_list = list(set(genre_list_split))\n",
    "#remove the value that is blank\n",
    "new_list.remove('')\n",
    "#inspect list of genres\n",
    "new_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Enriching the movies dataset by adding the various genres columns.\n",
    "movies_with_genres = movie_list.copy()\n",
    "\n",
    "for genre in new_list :\n",
    "    movies_with_genres[genre] = movies_with_genres.apply(lambda _:int(genre in _.genres), axis = 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies_with_genres.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Calculating the sparsity\n",
    "no_of_users = len(ratings['userId'].unique())\n",
    "no_of_movies = len(ratings['movieId'].unique())\n",
    "\n",
    "sparsity = round(1.0 - len(ratings)/(1.0*(no_of_movies*no_of_users)),3)\n",
    "print(sparsity)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Counting the number of unique movies in the dataset.\n",
    "len(ratings['movieId'].unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Finding the average rating for movie and the number of ratings for each movie\n",
    "avg_movie_rating = pd.DataFrame(ratings.groupby('movieId')['rating'].agg(['mean','count']))\n",
    "avg_movie_rating['movieId']= avg_movie_rating.index"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# inspecting the average movie rating data frame\n",
    "avg_movie_rating.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(avg_movie_rating)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#calculate the percentile count. It gives the no of ratings at least 70% of the movies have\n",
    "np.percentile(avg_movie_rating['count'],70)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Get the average movie rating across all movies \n",
    "avg_rating_all=ratings['rating'].mean()\n",
    "avg_rating_all\n",
    "#set a minimum threshold for number of reviews that the movie has to have\n",
    "min_reviews=30\n",
    "min_reviews\n",
    "movie_score = avg_movie_rating.loc[avg_movie_rating['count']>min_reviews]\n",
    "movie_score.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(movie_score)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create a function for weighted rating score based off count of reviews\n",
    "def weighted_rating(x, m=min_reviews, C=avg_rating_all):\n",
    "    v = x['count']\n",
    "    R = x['mean']\n",
    "    # Calculation based on the IMDB formula\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Calculating the weighted score for each movie\n",
    "movie_score['weighted_score'] = movie_score.apply(weighted_rating, axis=1)\n",
    "movie_score.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#join movie details to movie ratings\n",
    "movie_score = pd.merge(movie_score,movies_with_genres,on='movieId')\n",
    "#join movie links to movie ratings\n",
    "#movie_score = pd.merge(movie_score,links,on='movieId')\n",
    "movie_score.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#list top scored movies over the whole range of movies\n",
    "pd.DataFrame(movie_score.sort_values(['weighted_score'],ascending=False)[['title','count','mean','weighted_score','genres']][:10])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Gives the best movies according to genre based on weighted score which is calculated using IMDB formula\n",
    "def best_movies_by_genre(genre,top_n):\n",
    "    return pd.DataFrame(movie_score.loc[(movie_score[genre]==1)].sort_values(['weighted_score'],ascending=False)[['title','count','mean','weighted_score']][:top_n])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#run function to return top recommended movies by genre\n",
    "best_movies_by_genre('Musical',10)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#run function to return top recommended movies by genre\n",
    "best_movies_by_genre('Action',10)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#run function to return top recommended movies by genre\n",
    "best_movies_by_genre('Children',10)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#run function to return top recommended movies by genre\n",
    "best_movies_by_genre('Drama',10)  "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating a data frame that has user ratings accross all movies in form of matrix used in matrix factorisation\n",
    "ratings_df = pd.pivot_table(ratings, index='userId', columns='movieId', aggfunc=np.max)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings_df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Apply low rank matrix factorization to find the latent features\n",
    "U, M = matrix_factorization_utilities.low_rank_matrix_factorization(ratings_df.as_matrix(),\n",
    "                                                                    num_features=5,\n",
    "                                                                    regularization_amount=1.0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#merging ratings and movies dataframes\n",
    "ratings_movies = pd.merge(ratings,movie_list, on = 'movieId')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings_movies.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ratings_movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Gets the other top 10 movies which are watched by the people who saw this particular movie\n",
    "def get_other_movies(movie_name):\n",
    "    #get all users who watched a specific movie\n",
    "    df_movie_users_series = ratings_movies.loc[ratings_movies['title']==movie_name]['userId']\n",
    "    #convert to a data frame\n",
    "    df_movie_users = pd.DataFrame(df_movie_users_series,columns=['userId'])\n",
    "    #get a list of all other movies watched by these users\n",
    "    other_movies = pd.merge(df_movie_users,ratings_movies,on='userId')\n",
    "    #get a list of the most commonly watched movies by these other user\n",
    "    other_users_watched = pd.DataFrame(other_movies.groupby('title')['userId'].count()).sort_values('userId',ascending=False)\n",
    "    other_users_watched['perc_who_watched'] = round(other_users_watched['userId']*100/other_users_watched['userId'][0],1)\n",
    "    return other_users_watched[:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Getting other top 10 movies which are watched by the people who saw 'Gone Girl'\n",
    "get_other_movies('Gone Girl (2014)')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "avg_movie_rating.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#only include movies with more than 10 ratings\n",
    "movie_plus_10_ratings = avg_movie_rating.loc[avg_movie_rating['count']>=10]\n",
    "print(len(movie_plus_10_ratings))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movie_plus_10_ratings"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filtered_ratings = pd.merge(movie_plus_10_ratings, ratings, on=\"movieId\")\n",
    "len(filtered_ratings)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "filtered_ratings.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create a matrix table with movieIds on the rows and userIds in the columns.\n",
    "#replace NAN values with 0\n",
    "movie_wide = filtered_ratings.pivot(index = 'movieId', columns = 'userId', values = 'rating').fillna(0)\n",
    "movie_wide.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#specify model parameters\n",
    "model_knn = NearestNeighbors(metric='cosine',algorithm='brute')\n",
    "#fit model to the data set\n",
    "model_knn.fit(movie_wide)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Gets the top 10 nearest neighbours got the movie\n",
    "def print_similar_movies(query_index) :\n",
    "    #get the list of user ratings for a specific userId\n",
    "    query_index_movie_ratings = movie_wide.loc[query_index,:].values.reshape(1,-1)\n",
    "    #get the closest 10 movies and their distances from the movie specified\n",
    "    distances,indices = model_knn.kneighbors(query_index_movie_ratings,n_neighbors = 11) \n",
    "    #write a lopp that prints the similar movies for a specified movie.\n",
    "    for i in range(0,len(distances.flatten())):\n",
    "        #get the title of the random movie that was chosen\n",
    "        get_movie = movie_list.loc[movie_list['movieId']==query_index]['title']\n",
    "        #for the first movie in the list i.e closest print the title\n",
    "        if i==0:\n",
    "            print('Recommendations for {0}:\\n'.format(get_movie))\n",
    "        else :\n",
    "            #get the indiciees for the closest movies\n",
    "            indices_flat = indices.flatten()[i]\n",
    "            #get the title of the movie\n",
    "            get_movie = movie_list.loc[movie_list['movieId']==movie_wide.iloc[indices_flat,:].name]['title']\n",
    "            #print the movie\n",
    "            print('{0}: {1}, with distance of {2}:'.format(i,get_movie,distances.flatten()[i]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_similar_movies(112552)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_similar_movies(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print_similar_movies(96079)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movies_with_genres.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Getting the movies list with only genres like Musical and other such columns\n",
    "movie_content_df_temp = movies_with_genres.copy()\n",
    "movie_content_df_temp.set_index('movieId')\n",
    "movie_content_df = movie_content_df_temp.drop(columns = ['movieId','title','genres'])\n",
    "movie_content_df = movie_content_df.as_matrix()\n",
    "movie_content_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(movie_content_df,movie_content_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Similarity of the movies based on the content\n",
    "cosine_sim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#create a series of the movie id and title\n",
    "indicies = pd.Series(movie_content_df_temp.index, movie_content_df_temp['title'])\n",
    "indicies "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Gets the top 10 similar movies based on the content\n",
    "def get_similar_movies_based_on_content(movie_index) :\n",
    "    sim_scores = list(enumerate(cosine_sim[movie_index]))\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "   \n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[0:11]\n",
    "    print(sim_scores)\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    print(movie_indices)\n",
    "    similar_movies = pd.DataFrame(movie_content_df_temp[['title','genres']].iloc[movie_indices])\n",
    "    return similar_movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "indicies[\"Skyfall (2012)\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "get_similar_movies_based_on_content(19338)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get ordered list of movieIds\n",
    "item_indices = pd.DataFrame(sorted(list(set(ratings['movieId']))),columns=['movieId'])\n",
    "#add in data frame index value to data frame\n",
    "item_indices['movie_index']=item_indices.index\n",
    "#inspect data frame\n",
    "item_indices.head()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#get ordered list of movieIds\n",
    "user_indices = pd.DataFrame(sorted(list(set(ratings['userId']))),columns=['userId'])\n",
    "#add in data frame index value to data frame\n",
    "user_indices['user_index']=user_indices.index\n",
    "#inspect data frame\n",
    "user_indices.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#join the movie indices\n",
    "df_with_index = pd.merge(ratings,item_indices,on='movieId')\n",
    "#join the user indices\n",
    "df_with_index=pd.merge(df_with_index,user_indices,on='userId')\n",
    "#inspec the data frame\n",
    "df_with_index.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import train_test_split module\n",
    "from sklearn.model_selection import train_test_split\n",
    "#take 80% as the training set and 20% as the test set\n",
    "df_train, df_test= train_test_split(df_with_index,test_size=0.2)\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_test.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_users = ratings.userId.unique().shape[0]\n",
    "n_items = ratings.movieId.unique().shape[0]\n",
    "print(n_users)\n",
    "print(n_items)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = np.zeros((n_users, n_items))\n",
    "    #for every line in the data\n",
    "for line in df_train.itertuples():\n",
    "    #set the value in the column and row to \n",
    "    #line[1] is userId, line[2] is movieId and line[3] is rating, line[4] is movie_index and line[5] is user_index\n",
    "    train_data_matrix[line[5], line[4]] = line[3]\n",
    "train_data_matrix.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Create two user-item matrices, one for training and another for testing\n",
    "test_data_matrix = np.zeros((n_users, n_items))\n",
    "    #for every line in the data\n",
    "for line in df_test[:1].itertuples():\n",
    "    #set the value in the column and row to \n",
    "    #line[1] is userId, line[2] is movieId and line[3] is rating, line[4] is movie_index and line[5] is user_index\n",
    "    #print(line[2])\n",
    "    test_data_matrix[line[5], line[4]] = line[3]\n",
    "    #train_data_matrix[line['movieId'], line['userId']] = line['rating']\n",
    "test_data_matrix.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame(train_data_matrix).head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train['rating'].max()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    #select prediction values that are non-zero and flatten into 1 array\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten() \n",
    "    #select test values that are non-zero and flatten into 1 array\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    #return RMSE between values\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Calculate the rmse sscore of SVD using different values of k (latent features)\n",
    "rmse_list = []\n",
    "for i in [1,2,5,20,40,60,100,200]:\n",
    "    #apply svd to the test data\n",
    "    u,s,vt = svds(train_data_matrix,k=i)\n",
    "    #get diagonal matrix\n",
    "    s_diag_matrix=np.diag(s)\n",
    "    #predict x with dot product of u s_diag and vt\n",
    "    X_pred = np.dot(np.dot(u,s_diag_matrix),vt)\n",
    "    #calculate rmse score of matrix factorisation predictions\n",
    "    rmse_score = rmse(X_pred,test_data_matrix)\n",
    "    rmse_list.append(rmse_score)\n",
    "    print(\"Matrix Factorisation with \" + str(i) +\" latent features has a RMSE of \" + str(rmse_score))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Convert predictions to a DataFrame\n",
    "mf_pred = pd.DataFrame(X_pred)\n",
    "mf_pred.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_names = pd.merge(ratings,movie_list,on='movieId')\n",
    "df_names.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#choose a user ID\n",
    "user_id = 1\n",
    "#get movies rated by this user id\n",
    "users_movies = df_names.loc[df_names[\"userId\"]==user_id]\n",
    "#print how many ratings user has made \n",
    "print(\"User ID : \" + str(user_id) + \" has already rated \" + str(len(users_movies)) + \" movies\")\n",
    "#list movies that have been rated\n",
    "users_movies"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "user_index = df_train.loc[df_train[\"userId\"]==user_id]['user_index'][:1].values[0]\n",
    "#get movie ratings predicted for this user and sort by highest rating prediction\n",
    "sorted_user_predictions = pd.DataFrame(mf_pred.iloc[user_index].sort_values(ascending=False))\n",
    "#rename the columns\n",
    "sorted_user_predictions.columns=['ratings']\n",
    "#save the index values as movie id\n",
    "sorted_user_predictions['movieId']=sorted_user_predictions.index\n",
    "print(\"Top 10 predictions for User \" + str(user_id))\n",
    "#display the top 10 predictions for this user\n",
    "pd.merge(sorted_user_predictions,movie_list, on = 'movieId')[:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#count number of unique users\n",
    "numUsers = df_train.userId.unique().shape[0]\n",
    "#count number of unitque movies\n",
    "numMovies = df_train.movieId.unique().shape[0]\n",
    "print(len(df_train))\n",
    "print(numUsers) \n",
    "print(numMovies) "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Separate out the values of the df_train data set into separate variables\n",
    "Users = df_train['userId'].values\n",
    "Movies = df_train['movieId'].values\n",
    "Ratings = df_train['rating'].values\n",
    "print(Users),print(len(Users))\n",
    "print(Movies),print(len(Movies))\n",
    "print(Ratings),print(len(Ratings))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import libraries\n",
    "import keras\n",
    "from keras.layers import Embedding, Reshape, Merge\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.utils import plot_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Couting no of unique users and movies\n",
    "len(ratings.userId.unique()), len(ratings.movieId.unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Assigning a unique value to each user and movie in range 0,no_of_users and 0,no_of_movies respectively.\n",
    "ratings.userId = ratings.userId.astype('category').cat.codes.values\n",
    "ratings.movieId = ratings.movieId.astype('category').cat.codes.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Splitting the data into train and test.\n",
    "train, test = train_test_split(ratings, test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_users, n_movies = len(ratings.userId.unique()), len(ratings.movieId.unique())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Returns a neural network model which performs matrix factorisation\n",
    "def matrix_factorisation_model_with_n_latent_factors(n_latent_factors) :\n",
    "    movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "    movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='Movie-Embedding')(movie_input)\n",
    "    movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "    user_input = keras.layers.Input(shape=[1],name='User')\n",
    "    user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='User-Embedding')(user_input))\n",
    "    prod = keras.layers.merge([movie_vec, user_vec], mode='dot',name='DotProduct')\n",
    "    \n",
    "    model = keras.Model([user_input, movie_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = matrix_factorisation_model_with_n_latent_factors(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Training the model\n",
    "history = model.fit([train.userId, train.movieId], train.rating, epochs=50, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_hat = np.round(model.predict([test.userId, test.movieId]),0)\n",
    "y_true = test.rating"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_true, y_hat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Getting summary of movie embeddings\n",
    "movie_embedding_learnt = model.get_layer(name='Movie-Embedding').get_weights()[0]\n",
    "pd.DataFrame(movie_embedding_learnt).describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Getting summary of user embeddings from the model\n",
    "user_embedding_learnt = model.get_layer(name='User-Embedding').get_weights()[0]\n",
    "pd.DataFrame(user_embedding_learnt).describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.constraints import non_neg"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Returns a neural network model which performs matrix factorisation with additional constraint on embeddings(that they can't be negative)\n",
    "def matrix_factorisation_model_with_n_latent_factors_and_non_negative_embedding(n_latent_factors) :\n",
    "    movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "    movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors, name='Non-Negative-Movie-Embedding',embeddings_constraint=non_neg())(movie_input)\n",
    "    movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "\n",
    "    user_input = keras.layers.Input(shape=[1],name='User')\n",
    "    user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors,name='Non-Negative-User-Embedding',embeddings_constraint=non_neg())(user_input))\n",
    "    prod = keras.layers.merge([movie_vec, user_vec], mode='dot',name='DotProduct')\n",
    "    \n",
    "    model = keras.Model([user_input, movie_input], prod)\n",
    "    model.compile('adam', 'mean_squared_error')\n",
    "    \n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2 = matrix_factorisation_model_with_n_latent_factors_and_non_negative_embedding(5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model2.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history_nonneg = model2.fit([train.userId, train.movieId], train.rating, epochs=50, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "movie_embedding_learnt = model2.get_layer(name='Non-Negative-Movie-Embedding').get_weights()[0]\n",
    "pd.DataFrame(movie_embedding_learnt).describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_hat = np.round(model2.predict([test.userId, test.movieId]),0)\n",
    "y_true = test.rating"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_absolute_error(y_true, y_hat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Returns a neural network model which does recommendation\n",
    "def neural_network_model(n_latent_factors_user, n_latent_factors_movie):\n",
    "    \n",
    "    movie_input = keras.layers.Input(shape=[1],name='Item')\n",
    "    movie_embedding = keras.layers.Embedding(n_movies + 1, n_latent_factors_movie, name='Movie-Embedding')(movie_input)\n",
    "    movie_vec = keras.layers.Flatten(name='FlattenMovies')(movie_embedding)\n",
    "    movie_vec = keras.layers.Dropout(0.2)(movie_vec)\n",
    "\n",
    "\n",
    "    user_input = keras.layers.Input(shape=[1],name='User')\n",
    "    user_vec = keras.layers.Flatten(name='FlattenUsers')(keras.layers.Embedding(n_users + 1, n_latent_factors_user,name='User-Embedding')(user_input))\n",
    "    user_vec = keras.layers.Dropout(0.2)(user_vec)\n",
    "\n",
    "\n",
    "    concat = keras.layers.merge([movie_vec, user_vec], mode='concat',name='Concat')\n",
    "    concat_dropout = keras.layers.Dropout(0.2)(concat)\n",
    "    dense = keras.layers.Dense(100,name='FullyConnected')(concat)\n",
    "    dropout_1 = keras.layers.Dropout(0.2,name='Dropout')(dense)\n",
    "    dense_2 = keras.layers.Dense(50,name='FullyConnected-1')(concat)\n",
    "    dropout_2 = keras.layers.Dropout(0.2,name='Dropout')(dense_2)\n",
    "    dense_3 = keras.layers.Dense(20,name='FullyConnected-2')(dense_2)\n",
    "    dropout_3 = keras.layers.Dropout(0.2,name='Dropout')(dense_3)\n",
    "    dense_4 = keras.layers.Dense(10,name='FullyConnected-3', activation='relu')(dense_3)\n",
    "\n",
    "\n",
    "    result = keras.layers.Dense(1, activation='relu',name='Activation')(dense_4)\n",
    "    adam = Adam(lr=0.005)\n",
    "    model = keras.Model([user_input, movie_input], result)\n",
    "    model.compile(optimizer=adam,loss= 'mean_absolute_error')\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model3 = neural_network_model(10,13)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "history_neural_network = model3.fit([train.userId, train.movieId], train.rating, epochs=50, verbose=0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model3.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_hat = np.round(model3.predict([test.userId, test.movieId]),0)\n",
    "y_true = test.rating"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_absolute_error(y_true, y_hat)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}